{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "foIEx__DV_aS"
      },
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-F9VTidMWHb-",
        "outputId": "c5da3c9d-780e-4beb-ecfd-98116e904e17"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYpUommWWI41",
        "outputId": "38dd970e-2a0e-4ab9-ad3f-51d4fcc21618"
      },
      "source": [
        "%cd /content/gdrive/My Drive/NNFL/Assignment1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/NNFL/Assignment1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaVtdDg0WPAX"
      },
      "source": [
        "# function for normalising data\n",
        "def norm(data):\n",
        "  # norm_data = data\n",
        "  mean = np.mean(data)\n",
        "  std = np.std(data)\n",
        "  norm_data = (data-mean)/std\n",
        "  return norm_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58UPrlyeXt3P"
      },
      "source": [
        "def likelihood(x, meanmat, covariance):\n",
        "  n = len(x)\n",
        "  coeff = 1 /((( 2 * np.pi )** (7/2) )*np.linalg.det(covariance)** 0.5 )\n",
        "  l = coeff*np.exp(- 0.5 * np.dot(np.dot((x - meanmat),np.linalg.inv(covariance)),(x - meanmat).T))\n",
        "  return l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfZ8LvIXXpv-"
      },
      "source": [
        "def MLrule(x_testing, x, y):\n",
        "  # splitting the input data into it's different classes\n",
        "  x1 = np.array([x[i] for (i, val) in enumerate(y) if val == 1 ])\n",
        "  x2 = np.array([x[i] for (i, val) in enumerate(y) if val == 2 ])\n",
        "  x3 = np.array([x[i] for (i, val) in enumerate(y) if val == 3 ])\n",
        "\n",
        "  m1 = np.mean(x1, axis = 0)\n",
        "  m2 = np.mean(x2, axis = 0)\n",
        "  m3 = np.mean(x3, axis = 0)\n",
        "  cov1 = np.cov(np.transpose(x1.astype(float)))\n",
        "  cov2 = np.cov(x2.astype(float).T)\n",
        "  cov3 = np.cov(x3.astype(float).T)\n",
        "\n",
        "  # likelihood\n",
        "  l1 = likelihood(x_testing, m1, cov1)\n",
        "  l2 = likelihood(x_testing, m2, cov2)\n",
        "  l3 = likelihood(x_testing, m3, cov3)\n",
        "\n",
        "  # output\n",
        "  if max(l1, l2, l3) == l1:\n",
        "    return 1\n",
        "  elif max(l1, l2, l3) == l2:\n",
        "    return 2\n",
        "  else:\n",
        "    return 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tjwtX45Yz-R"
      },
      "source": [
        "def confusion_mat(y_predicted, y_testing):\n",
        "  conf_mat = np.zeros((3,3))\n",
        "  for i in range(len(y_testing)):\n",
        "    if y_testing[i] == 1:\n",
        "      if y_predicted[i] == 1:\n",
        "        conf_mat [0][0] += 1\n",
        "      if y_predicted[i] == 2:\n",
        "        conf_mat [0][1] += 1\n",
        "      if y_predicted[i] == 3:\n",
        "        conf_mat [0][2] += 1\n",
        "    if y_testing[i] == 2:\n",
        "      if y_predicted[i] == 1:\n",
        "        conf_mat [1][0] += 1\n",
        "      if y_predicted[i] == 2:\n",
        "        conf_mat [1][1] += 1\n",
        "      if y_predicted[i] == 3:\n",
        "        conf_mat [1][2] += 1\n",
        "    if y_testing[i] == 3:\n",
        "      if y_predicted[i] == 1:\n",
        "        conf_mat [2][0] += 1\n",
        "      if y_predicted[i] == 2:\n",
        "        conf_mat [2][1] += 1\n",
        "      if y_predicted[i] == 3:\n",
        "        conf_mat [2][2] += 1\n",
        "  return conf_mat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKBSif6CWRDE"
      },
      "source": [
        "# extracting the data\n",
        "data = pd.read_excel(\"data_q6_q7.xlsx\")\n",
        "data = np.asarray(data)\n",
        "data = np.random.permutation(data)\n",
        "print(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kCO2R4UWUAU"
      },
      "source": [
        "# splitting into input and output\n",
        "X = data[:, :-1]  #input\n",
        "y = data[:,-1]    #output\n",
        "\n",
        "# normalizing X and y\n",
        "X = norm(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHqUVIX1WXXg"
      },
      "source": [
        "rows = X.shape[0]\n",
        "X_training = X[0 : int(rows*0.7)]\n",
        "X_testing = X[int(rows*0.7) : rows+1]\n",
        "y_training = y[0 : int(rows*0.7)]\n",
        "y_testing = y[int(rows*0.7) : rows+1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwYev-ayXHa4",
        "outputId": "b412aaa3-511b-42aa-8f9a-dc1d42edcff4"
      },
      "source": [
        "ind_acc1 = []\n",
        "ind_acc2 = []\n",
        "ind_acc3 = []\n",
        "overall_acc = []\n",
        "y_predicted = []\n",
        "for i in range(len(X_testing)):\n",
        "  y_predicted.append(MLrule(X_testing[i], X_training, y_training))\n",
        "# print(y_predicted, y_testing)\n",
        "conf_mat = confusion_mat(y_predicted, y_testing)\n",
        "# individual accuracy\n",
        "ind_acc1 = conf_mat[ 0 ][ 0 ]/sum(conf_mat[ 0 ])\n",
        "#  ind_acc1.append(acc1)\n",
        "ind_acc2 = conf_mat[ 1 ][ 1 ]/sum(conf_mat[ 1 ])\n",
        "#ind_acc2.append(acc2)\n",
        "ind_acc3 = conf_mat[ 2 ][ 2 ]/sum(conf_mat[ 2 ])\n",
        "# ind_acc3.append(acc3)\n",
        "  # overall accuracy\n",
        "overall_acc = (conf_mat[ 0 ][ 0 ] + conf_mat[ 1 ][ 1 ] + conf_mat[ 2 ][ 2 ])/np.sum(conf_mat)\n",
        "# overall_acc.append(acc)\n",
        "# avg_ind_acc1 = sum(ind_acc1)/len(ind_acc1)\n",
        "# avg_ind_acc2 = sum(ind_acc2)/len(ind_acc2)\n",
        "# avg_ind_acc3 = sum(ind_acc3)/len(ind_acc3)\n",
        "# avg_overall_acc = sum(overall_acc)/len(overall_acc)\n",
        "print(\"Individual accuracy of class 1:\", ind_acc1)\n",
        "print(\"Individual accuracy of class 2:\", ind_acc2)\n",
        "print(\"Individual accuracy of class 3:\", ind_acc3)\n",
        "print(\"Overall accuracy:\", overall_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Individual accuracy of class 1: 0.8333333333333334\n",
            "Individual accuracy of class 2: 0.9444444444444444\n",
            "Individual accuracy of class 3: 0.9047619047619048\n",
            "Overall accuracy: 0.8888888888888888\n"
          ]
        }
      ]
    }
  ]
}